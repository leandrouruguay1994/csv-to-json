# Streaver - CSV to JSON Normalizer

AplicaciÃ³n Streamlit que procesa archivos CSV, normaliza los datos y los almacena en PostgreSQL, generando archivos JSON formateados.

## CaracterÃ­sticas

- ğŸ“Š Interfaz web con Streamlit
- ï¿½ API REST con FastAPI para acceso programÃ¡tico
- ï¿½ğŸ”„ NormalizaciÃ³n de nÃºmeros telefÃ³nicos a formato xxx-xxx-xxxx
- ğŸ—„ï¸ Almacenamiento en PostgreSQL con dos tablas (original y normalizada)
- ğŸ“ ExportaciÃ³n a JSON con formato indentado (2 espacios) y claves ordenadas
- âœ… ValidaciÃ³n de datos y reporte de errores por lÃ­nea
- ğŸ“ˆ Ordenamiento alfabÃ©tico por apellido y nombre
- ğŸ“Š Conteo de color mÃ¡s popular entre los registros de los csvs.

![Diagrama del Sistema](diagram.jpg)

## Estructura del Proyecto

```
Streaver/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              
â”‚   â”œâ”€â”€ assets/
â”‚   â”‚   â””â”€â”€ image.png        
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ database.py      
â”‚       â””â”€â”€ normalizer.py    
â”œâ”€â”€ api/
â”‚   â””â”€â”€ api.py                
â”œâ”€â”€ datasets/ 
â”‚       â”œâ”€â”€ dataset1.csv
â”‚       â”œâ”€â”€ dataset2.csv
â”‚       â””â”€â”€ dataset3.csv               
â”œâ”€â”€ Dockerfile               
â”œâ”€â”€ docker-compose.yml       
â”œâ”€â”€ requirements.txt         
â”œâ”€â”€ diagram.png              
â”œâ”€â”€ .env                     
â””â”€â”€ README.md                
```

## Requisitos

- Python 3.11+
- PostgreSQL 15+
- Docker y Docker Compose (opcional)

## InstalaciÃ³n

1. Clonar el repositorio
2. Copiar el archivo de configuraciÃ³n:

```powershell
Copy-Item .env.example .env
```

3. Iniciar los servicios:

```
docker-compose up -d
```

## Acceso a los Servicios

Una vez levantados los contenedores:

- **Streamlit UI**: http://localhost:8501
- **API Docs (Swagger)**: http://localhost:8000/docs
- **PostgreSQL**: localhost:5432

### Endpoints Principales:

```bash
# Health check
curl http://localhost:8000/health

# Subir CSV
curl -X POST "http://localhost:8000/upload" \
  -F "file=@datasets/format1_example.csv"
```

## Uso de Streamlit

1. Abrir la aplicaciÃ³n en el navegador
2. Cargar un archivo CSV con las columnas
3. Hacer clic en "Process and Normalize Data"
4. Revisar los resultados normalizados
5. Descargar el archivo `result.json` generado

### Ejemplo de JSON de Salida

```json
{
  "entries": [
    {
      "firstname": "John",
      "lastname": "Doe",
      "phonenumber": "123-456-7890",
      "zipcode": "12345",
      "color": "red"
    },
    {
      "firstname": "Jane",
      "lastname": "Smith",
      "phonenumber": "555-123-4567",
      "zipcode": "54321",
      "color": "blue"
    }
  ],
  "errors": []
}
```

## Reglas de NormalizaciÃ³n

1. **NÃºmeros telefÃ³nicos**: Se convierten al formato `xxx-xxx-xxxx`
2. **CÃ³digos postales**: Se validan formatos de 5 dÃ­gitos
3. **Ordenamiento**: Las entradas se ordenan alfabÃ©ticamente por `(lastname, firstname)`
4. **Errores**: Las lÃ­neas con errores se registran en la lista `errors` con su nÃºmero de lÃ­nea
5. **JSON**: Salida con indentaciÃ³n de 2 espacios y claves ordenadas ascendentemente

## Tablas de Base de Datos

### original_data
- `id`: Serial Primary Key
- `upload_timestamp`: Timestamp
- `raw_data`: JSONB (datos originales del CSV)

### normalized_data
- `id`: Serial Primary Key
- `upload_timestamp`: Timestamp
- `firstname`: VARCHAR(255)
- `lastname`: VARCHAR(255)
- `phonenumber`: VARCHAR(20)
- `zipcode`: VARCHAR(10)
- `color`: VARCHAR(50)
- `original_id`: Foreign Key a original_data

## TecnologÃ­as

- **Streamlit**: Framework de interfaz web
- **PostgreSQL**: Base de datos relacional
- **Pandas**: Procesamiento de datos
- **psycopg2**: Conector PostgreSQL
- **Docker**: ContenerizaciÃ³n

## Futuros desarrollos

1) Desplegar la aplicaciÃ³n en un servicio cloud (AWS/Azure/GCP) para garantizar disponibilidad y persistencia continua.
2) Implementar arquitectura de datos medallion (Bronze â†’ Silver â†’ Gold) en PostgreSQL para mejor gestiÃ³n de calidad y transformaciÃ³n de datos.
3) Integrar DBT (Data Build Tool) para orquestar y gestionar las transformaciones de datos entre capas.

